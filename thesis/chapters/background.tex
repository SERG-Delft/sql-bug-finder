\chapter{Background}
\label{chapter:background}

SQL is a domain specific language used in handling structured data held in a relational database management system. In this chapter, we discuss technologies related to the thesis and give background information to the problem at hand. This chapter is divided in two main sections. In Section \ref{section:sql_bugs} bugs in SQL are explained and related work on the topic of identifying semantic bugs in SQL is shown. In Section \ref{section:data_collection_from_stack_overflow} the importance of StackOverflow as a source for collecting relevant data is discussed and previous research on this topic is presented.

\section{Bugs in SQL queries}
\label{section:sql_bugs}
We organized the collected previous work related to bugs in SQL queries in four different categories: semantic bugs in SQL, teaching systems for SQL, empirical studies on SQL queries and testing SQL queries. In the following subsections we present each category together with the most relevant work that we identified. We give an overview of previous studies per research area in Table \ref{table:bugs_in_sql_overview}.

\begin{center}
\begin{tabularx}{\linewidth}{lXXr}
\toprule
\textbf{Research area} & \multicolumn{2}{X}{\textbf{References}} & \textbf{Qty} \\ \midrule
Semantic bugs in SQL & \multicolumn{2}{X}{\cite{P001} \cite{P002} \cite{P016} \cite{P019} \cite{P998}} & 5 \\
Teaching systems for SQL & \multicolumn{2}{X}{\cite{P004} \cite{P037} \cite{P005} \cite{P006} \cite{P017} \cite{P036}} & 6 \\
Empirical studies on SQL queries & \multicolumn{2}{X}{\cite{P008} \cite{P009} \cite{P010} \cite{P015}} & 4 \\
Testing SQL queries & \multicolumn{2}{X}{\cite{P011} \cite{P013} \cite{P014}} & 3 \\ \midrule
\textbf{Total} &  &  & \textbf{18} \\ \bottomrule
\caption{Literature collection related to bugs in SQL queries}
\label{table:bugs_in_sql_overview}
\end{tabularx}
\end{center}

\subsection{Semantic bugs in SQL}

The work of \citet{P001} and \citet{P002} was the first to focus on the class of SQL queries which are correct from a syntactic point of view but contain semantic issues, regardless of the query task. The authors classify SQL errors in two groups, one related to syntactic issues and the other to semantic ones. In the first group, the database management system will detect the error since the query can not be executed at all. These errors are usually easier to detect and fix since the developer gets an immediate error or warning when trying to run the query. In the second group, the queries are correct however they do not produce the intended results. These types of errors are harder to detect and fix since the problem is not immediately obvious.

In their work, the authors further classify semantic errors in two groups, one for which the task must be known beforehand and another where the single SQL query is enough to detect semantic issues. The focus is then placed on the second group and this is also the case for this thesis. The main contribution of their work represents a taxonomy of semantic errors which frequently appear in SQL queries collected from homework and exam materials for one of the database courses at the University of Halle. 

Apart from this list, \citet{P019} carried out another study for analysing two other specific types of semantic issues that appear in SQL queries, more specifically inconsistent conditions and queries which might generate runtime errors. One potential threat to validity for their work is represented by the limited size of the dataset on which the study was conducted, more specifically the errors were extracted from six SQL questions that appeared on two exams with roughly 150 participants. It is worth pointing out that \citet{P003} carried out a study using the same taxonomy of semantic bugs on a larger dataset, however the queries were still extracted from previous exams. In this thesis, apart from implementing a tool for detecting these semantic errors, a study on a large dataset of queries extracted from real-world applications from StackOverflow is also conducted which brings further insight into how these issues appear.

An extensive taxonomy of SQL code smells is also presented by \citet{P998}. In his book, the author presents the most frequently encountered SQL antipatterns and pitfalls. The provided list of issues also takes into account the most common SQL problems which the author encountered while answering various question posts on online forums, mailing lists and newsgroups over a time period of more than 15 years. The book places the antipatterns in one of the following categories: logical database design, physical database design, query related and finally application development issues. In the query related category, we find the most common types of semantic issues encountered in SQL queries (also defined as code smells), more specifically a list of six query antipatterns: fear of the unknown, related to the special nature of \sql{NULL} in SQL, ambiguous groups, which relates to the use of the \sql{GROUP BY} clause, the random selection antipattern, related to the issue when some random row is selected from the database and finally the implicit columns issue which refers to use of the select all star operator (\sql{*}) in \sql{SELECT} statements instead of providing an explicit select list. A large number of subsequent studies are based on the taxonomy provided in this book in an effort to both analyse as well as better understand how and why these issues appear in SQL queries.

\subsection{Empirical studies in SQL education}

Other similar studies presented by \citet{P004, P037, P005} and \citet{P006} focus on building knowledge based teaching systems for SQL. The authors in these studies present two very similar systems which are intended to be used as guided discovery learning environments for SQL. The motivation behind building such systems is that although SQL is a relatively simple and highly structured language, students still have many difficulties when first learning it, therefore such intelligent teaching systems aim to overcome these difficulties and serve as an additional practice environment for SQL learners. Furthermore, both of the presented systems focus on detecting semantic errors in SQL queries since syntactic problems can already be detected by the database engines. 

Moreover, the two approaches presented in these papers also require having knowledge about the task which has to be solved, in the form of  a correct query for a given SQL question. In contrast, the approach taken in this thesis assumes no such knowledge which makes the tools and algorithms work for queries written at large, not only in a teaching environment. The system built by \citet{P004} only works on \sql{SELECT} SQL statements while the one presented by \citet{P005} works for \sql{SELECT} and \sql{CREATE VIEW} statements. The approach taken in this thesis is such that the rule-based semantic error detection tool should work on all SQL statements. Finally, in both of the previously mentioned studies, the presented tools for detecting semantic issues in SQL were tested on fairly small datasets which only contained SQL statements originating from assignments or exams, nevertheless the research did show the great potential these tools have in a teaching environment, helping most students better understand the SQL syntax.

In \citet{P017} and \citet{P036}, further SQL teaching practices in higher education are also presented as well as an overview of educational SQL research topics and most frequent issues which appear in SQL queries written by students. As with other previous research, the authors note that future studies should be carried out on more diverse datasets, with queries from real world projects, in an effort to understand whether their findings generalize on software at large as well, an aspect which we try to address in this thesis.

\subsection{Empirical studies on SQL queries}

Another interesting study that focuses on conducting the first large-scale quantitative analysis of syntactic errors that appear in SQL queries written by students is presented by \citet{P008}. Apart from going over the most common mistakes that students make, the study also describes how an automatic classifier can be used in predicting the performance of students when writing SQL statements. Although the paper is not directly concerned with analysing semantic errors in SQL, the authors point out that in most cases students abandon answering an SQL related question due to a syntactic error. Their findings show that syntax errors in different clauses of the \sql{SELECT} statement, undefined referred column errors and grouping errors are the most common types of mistakes that novices SQL users make when writing their statements. 

It is therefore interesting to point out that while semantic errors are the ones requiring more knowledge and a deeper understanding of the underlying SQL principles in order to solve, students will most certainly not come to grips with these while the query formulation contains syntax errors, as the authors of the study also conclude. 

Furthermore, in a subsequent study \citet{P009} also conduct the first large-scale analysis of semantic mistakes in SQL \sql{SELECT} queries written by students. The dataset used in this paper contained queries pertaining to seven different key SQL concepts: \sql{GROUP BY} without \sql{HAVING}, self \sql{JOIN}, \sql{GROUP BY}, natural \sql{JOIN}, simple subquery, simple query with only one table and finally correlated subqueries. Again, the study also made use of knowledge related to the question for which the SQL statement was written, therefore a query was considered semantically incorrect when the result set returned by it was different from the one returned by the accepted solution query. The authors find out that the majority of semantic bugs are of type omission, showing that students have trouble in selecting the correct type of query to use as well as lack a systematic approach to formulating the query. Queries that require a \sql{JOIN}, a subquery or a \sql{GROUP BY} are the most susceptible to these types of omission errors. Furthermore, results also show that the majority of semantic mistakes occur in the \sql{WHERE} clause of the \sql{SELECT} statement which, as the authors point out, might be the result of memory overload when dealing with complex queries.

Another large-scale study on SQL code smells, which investigates the prevalence, impact, evolution and co-occurrence of SQL code smells with traditional code smells was conducted by \citet{P010}. In their work, they analysed 150 open source software projects which made use of popular database access APIs such as JDBC, JPA and Hibernate, in an attempt to investigate how often SQL code smells appear in these systems. 

While traditional code smell detection has been an important research topic for several years now, recently there has been growing interest in analysing and detecting such code smells in SQL code. The authors of this study make use of the SQLInspect tool and focus on analysing four SQL code smells. These code smells were selected from the extensive catalog published by \citet{P998}, which is the first book to present a comprehensive list of SQL antipatterns. More specifically, the authors of the study looked at implicit columns code smells, where the select all operator (\sql{*}) is used instead of a smaller list which has implications on network bandwidth wastage, improper handling of \sql{NULL} values smells, where comparison operators are used instead of the \sql{IS NULL} or \sql{IS NOT NULL} expressions, ambiguous grouping code smells, where \sql{GROUP BY} clause terms are misused and finally random selection smells when developers query a single random row wrestling in a full scan of the table. 

The findings of the research indicate that SQL code smells indeed exists persistently in data-intensive systems, however these are independent from other traditional code smells. The most prevalent code smell was the use of the select all operator, the implicit columns usage smell. Also quite an interesting finding is that SQL code smells have a weaker association with bugs than traditional code smells as well as the fact that SQL smells are more likely to be introduced at the start of the project, and are not addressed as quickly as other more traditional smells, which might also be due to the fact that tools for detecting and informing developers about these issues are not yet in place or not widely adopted enough.

In a recent study by \citet{P015} the author presents a detailed analysis on the types of SQL errors which are most likely to be encountered in SQL queries formulated by novice users. Furthermore, the author also attempts to explain the causes behind the most common errors. The study uses a taxonomy of different syntactic and semantic SQL errors previously defined by \citet{P016} in their work on errors and complications in the formulation of SQL queries as well as a dataset of queries collected from four iterations of an SQL course. The reported results show that the three most common errors were missing expressions, extraneous or omitted grouping columns and missing join statements. 

Moreover, the authors observed that the cause of the error is strongly related to the query concept rather than the error type. The study finally recommends a way to mitigate the three most commonly encountered errors in SQL queries by teaching students techniques for recognizing natural language patterns and their SQL equivalents, before proceeding to writing more complex queries.

\subsection{Testing SQL queries}

An interesting study on generating test data for SQL queries is presented by \citet{P011}. As with any other piece of code, testing is of utmost importance in order to guarantee that software is working correctly, and this should also be the case for applications involving SQL queries. In their work, the authors model the problem of generating test data for SQL queries as a search-based problem and present three novel approaches, based on search algorithms, to solving this problem. More specifically, the paper proposes using genetic algorithms, random search and biased random search and analyses each approach on three open source projects and one industrial software system. 

The algorithms take as input some SQL query to be tested as well as the database schema and use the three different techniques for populating the tables with test data which should meet certain testing criteria. The results show that the genetic algorithm approach is able to cover 98.6\% of all queries in the dataset and also has the advantage of being able to properly test queries with \sql{JOIN} statements, multiple subqueries as well as string manipulation functions. One of the main contributions of the research was the implementation of the EvoSQL tool for generating test data for SQL queries as well as an empirical study on the effectiveness and performance of the tool on a dataset of queries extracted from four different software projects. 

Furthermore, the study shows that full coverage for one query can be reached in almost all cases within 2 to 15 seconds, which makes the tool usable in a practical setting as well. The dataset collected for this paper will be used for testing the rule-based static analysis tool that we will present in this paper, in order to further analyse the prevalence of semantic bugs in queries extracted from different software projects.

In two other studies by \citet{P013, P014} we find the first attempt at implementing a tool for identifying code smells in SQL queries embedded in Java code. The tool uses a combination of static analysis techniques, together with database schemas as well as the data present in the database in order to detect potential semantic issues in SQL queries extracted from source code. 

Furthermore, depending on the context of the smell, the tool is also able to determine its severity. What is interesting for this research, is that the tool is provided both as a command line interface as well as an Eclipse plug-in, which should help with providing better support for developers as well as speed up adoption of the tool, something which most previous research in this area is lacking. 

It is worth mentioning that in \citet{P014} the authors provide an extensive evaluation of their tool on a number of open source Java projects of various complexity and size, with results showing the potential that such tools have for inspecting SQL queries.
The SQL code smells implemented by the authors of these studies again come from the book by \citet{P998} which provides a list of six common SQL antipatterns. 

Interestingly enough, the authors decided to not implement a detection rule for the issue concerning the unnecessary index scan, when a wildcard character is used at the beginning of a string for the \sql{LIKE} expression, which results in a missing access predicate, however our tool does detect this issue as well. The SQL code smell detector presented by the authors takes as input some SQL statements extracted from a source code file and optionally the schema of the database along with any database contents that might be present. After this, both the abstract syntax tree (AST) as well as the abstract semantic graph (ASG) are constructed, on which the implemented rules for detecting the various smells are run. As future work, the authors plan on extending the list of supported code smells for the detection tool as well as adding more features to the Eclipse plug-in.


\section{SQL data collection from StackOverflow}
\label{section:data_collection_from_stack_overflow}

With more than 10 million visits per day\footnote{\url{https://stackexchange.com/sites?view=list}} and 14 million active users, StackOverflow has become the main questions and answers website (Q\&A), related to programming, that exists on the internet. It was launched in 2008 and has quickly grown to now contain 21 million questions, 31 million answers, with an answer rate of 70\% and an average of 6500 questions new questions being asked on the platform every day. This huge popularity means that StackOverflow is now a large knowledge base for several programming languages and hence it represents a valuable resource for researchers to tap into. There have been numerous papers on extracting various types of information from StackOverflow, however only recently there has been some growing interest in extracting SQL related information from this website.

In \citet{P018} the authors present the first attempt at extracting SQL related information from StackOverflow, more specifically queries. The methods presented in the paper are the closest to our approach, however the authors make use of data dumps of StackOverflow provided by Stack Exchange in XML format, as opposed to our approach which makes use of real time data from the platform by taking advantage of the Stack Exchange API. Furthermore, the algorithm for extracting the SQL queries from the code block sections that we use for building our dataset is also different than the one presented in the paper. Finally, the study looks at whether the extracted queries are error prone by manually investigating the queries and reporting on some general descriptive statistics such as the number of joins per query or functions used. As the authors of the paper also conclude, the queries should further be investigated with automated tools for properly detecting issues, which is something that our study covers. Nevertheless, this does show the huge potential of the StackOverflow platform in extracting a large number of SQL queries for various research topics. Moreover, this should help in bridging the current gap which exists in this research field, in the sense that most studies on identifying semantic issues in SQL queries are conducted on datasets which come from SQL courses, where queries are written by students on either homework assignments or exams. By using these new mining techniques for extracting queries from StackOverflow this should now allow for building better datasets and obtaining new insight as to what types of issues might appear in queries found in real world applications.

Another study by \citet{P020}, uses information extracted from StackOverflow questions in an attempt to understand which programming concepts are the most confusing and whether there are any similarities across different languages. For this study, a number of programming languages were considered, among which Java, Python and SQL. By looking at the top words used, the authors were able to extract the concepts of a question post and build two categories one related to programming concepts and the other related to the type of information that users were looking for. Each question was then placed in either of the two categories. Furthermore, the questions were also clustered by using topic models, with one of the main findings of the paper being that the distribution over question types is not different among programming languages. This means that the types of questions being asked do not vary across programming languages. Interestingly, a method was also presented for how to identify what question types were mostly associated with a certain programming language, such as SQL for example, as well as a distribution of what are the most popular times of the week when users ask questions. As the authors of the study also conclude, this type of insight could be useful for future IDEs or smart documentation systems for providing guidance to developers depending on the context.

In \citet{P021} a study on C/C++ code weaknesses found in StackOverflow posts is presented. The aim of the paper is to analyse common weakness enumeration errors (CWE) \cite{P993, P994} in code snippets found on StackOverflow. This is especially important since such code might for example contain security vulnerabilities and sharing it carelessly might introduce these problems in other systems. The authors find out that 36\% of the CWE issue types are detected, particularly the improper restriction of operation within the bound of a memory buffer. More alarming, the study shows that the proportion of code which contains issues on StackOverflow has doubled from 2008 to 2018. For building the dataset, the authors first extract code snippets from StackOverflow answers tagged with the C/C++ tag. Furthermore, snippet codes with less than 5 lines of code are removed in order to reduce bias for frequent code. Finally, the paper uses the Gueslang\footnote{\url{https://github.com/yoeo/guesslang}} open source tool for detecting which of the extracted code snippets actually contain C/C++ code. This tool is shown to detect with a 90\% accuracy the programming language from a list of 20 pre-defined languages including C/C++. The authors also analysed the revision history of answer posts in order to detect whether issues are also corrected when detected by other users, which is not always the case or in some situations this happens with a big delay. This study therefore brings into discussion the issue of sharing bug-induced code on StackOverflow, which inexperienced developers might directly use in their applications without realizing the implications of potentially introducing errors or semantic issues into their systems. Prior studies by \citet{P022} and \citet{P023} show that code snippets on StackOverflow are indeed widely shared and used by developers and look into the implications that arise from this. Moreover, \citet{P025} build an open dataset containing code extracted from StackOverflow in order to provide a means for understanding how these snippets are maintained and evolve over time.

\citet{P024} present an interesting study on detecting the programming language used in StackOverflow code snippets. The authors look at two different methods for classifying the language used. The first one uses metadata provided by users such as tags and other filters. The second approach uses the GitHub linguist tool\footnote{\url{https://github.com/github/linguist}}, which according to the developers is an industry-strength library for automatically classifying code and identifying the underlying programming language used. The authors of the study remark that both approaches proved to be scalable enough to be employed on diverse code repositories of various sizes. The results of the paper however show that the two approaches produce results which are often not consistent, which indicates that these tools should be used with caution. This further indicates that a hybrid approach, which combines the strengths of both methods, user provided metadata as well as automatic detection tools, should be investigated in future research.

In \citet{P026} the authors construct a full island grammar which is capable of modelling Java tagged StackOverflow posts. The intention of the research was to build a heterogeneous abstract syntax tree (H-AST) for each post type in StackOverflow, that is questions, answers and comments, which is then used to construct a structured dataset for the posts information, to be used in future research. This solves one of the main problems with StackOverflow data mining, more specifically the heterogeneous nature of data which can be found in posts. Using the provided dataset, the contents of a post can be navigated by differentiating between code, which in this case is Java, and natural language fragments. Moreover, the authors also provided other meta information for each post in the dataset such as term frequency vectors and mentioned terms. In a previous study \citet{P027} present an interesting Eclipse plugin which leverages information from StackOverflow posts and provides assistance to developers using the active context in the IDE. More specifically, the plugin formulates queries to StackOverflow using the information available in the active context of the IDE and then presents a ranked list of results to the developer who can then directly insert the retrieved code from the posts.

Previous research has also used StackOverflow data to gain insights into trends and most common topics of interest in the development community. \citet{P029} and \citet{P030} use LDA modeling techniques to discover the most frequent topics present in post discussions. The studies also analyse these topics as well as their evolution over time and show the increasing popularity of web development and mobile applications related discussions. Similarly \citet{P031} use manual techniques to categorize Android related posts on StackOverflow and find dependencies between question types and certain problems, providing a better understanding of the most frequent issues appearing in mobile app development. This again shows the great potential of using the huge knowledge base that StackOverflow has become in extracting interesting information for various studies. Although we do not provide this analysis in our paper, it would be very interesting to use our collected dataset and perform LDA analysis on it in order to identify the main topics of interest for SQL related questions present in StackOverflow posts. Furthermore, it could also be very insightful to perform manual analysis on some of the posts for which our tool reports semantic issues found in the extracted queries, in order to understand whether developers notice the presence of these types of SQL issues as well as if the errors are addressed over time. Finally, \citet{P032} provide a complete overview and evaluation of current source code mining tools and techniques, mostly focused on sources such as code tracking websites or other APIs, however relevant nonetheless in presenting different methods for source code extraction. Other studies on mining source code from various APIs are also presented by \citet{P033}, \citet{P034} and \citet{P035}.
